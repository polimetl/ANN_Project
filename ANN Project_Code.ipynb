{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f8c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the necessary libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing the sklearn libraries\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Loading the tensorflow and keras modules\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b62ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv(\"Data_in_csv_formate\")\n",
    "df.head()\n",
    "\n",
    "# Correlating the features using pearson correlation \n",
    "df.corr()\n",
    "corrmat = df.corr()\n",
    "features = corrmat.index\n",
    "sns.heatmap(df[features].corr(), cmap=\"RdBu\", square=True)\n",
    "plt.rcParams.update({'font.weight': 'bold'})\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "for label in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "    label.set_fontweight('bold')\n",
    "plt.savefig(\"Storage_pathway_in_png_formate\", dpi=300,)\n",
    "plt.show()\n",
    "plt.figure(figsize=(50,20))\n",
    "\n",
    "# Plotting the feature importance score  \n",
    "model=ExtraTreesRegressor()\n",
    "model.fit(X,Y)\n",
    "print(model.feature_importances_)\n",
    "vd=pd.Series(model.feature_importances_,index=X.columns)\n",
    "vd.nlargest(14).plot(kind='bar')\n",
    "plt.ylabel(\"Feature Importance score\", fontsize = 18, fontweight='bold')\n",
    "plt.savefig(\"Storage_pathway_in_png_formate\", dpi=300,)\n",
    "plt.show()\n",
    "\n",
    "# Cpaturing the least important features \n",
    "corr_features = correlation(df, 0.9)\n",
    "len(set(corr_features))\n",
    "corr_features\n",
    "\n",
    "# Droppin out the least important features (if necessary) \n",
    "df.drop(corr_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937f48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Visualization for each numeric column\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Histogram + KDE\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(df[col], kde=True, bins=30, color=\"skyblue\")\n",
    "    plt.title(f\"Distribution of {col}\", fontsize=14)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1850c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "Y = df.iloc[:,-1]\n",
    "\n",
    "# Splitting the dataset into training and testing dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, train_size=0.80, test_size=0.20, random_state=42)\n",
    "print('Train/Test Sets Sizes : ',X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "\n",
    "# Standardization of the dataset\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b5de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model \n",
    "def build_model(n_neurons=%, learning_rate=%):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(n_neurons//2, activation='relu'))\n",
    "    model.add(Dense(1))  # Regression output\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "regressor = KerasRegressor(model=build_model, verbose=0)\n",
    "\n",
    "# Hyperparameter tuning optimization\n",
    "param_dist = {\n",
    "    \"model__n_neurons\": [32, 64, 128],\n",
    "    \"model__learning_rate\": [0.001, 0.01, 0.1],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "    \"epochs\": [50, 100, 200]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=regressor,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,\n",
    "    cv=3,\n",
    "    scoring='r2',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472d5b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=random_search.predict(X_train)\n",
    "y_pred_nn = random_search.predict(X_test)\n",
    "\n",
    "# Capturing the loss with hyperparameter towards global minima\n",
    "history = random_search.fit(X_train, Y_train, validation_split = 0.2, epochs = 200)\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs =range(1, len(loss)+1)\n",
    "plt.rcParams.update({'font.weight': 'bold'})\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.tick_params(axis='both', \n",
    "                direction='in',         \n",
    "                width=2) \n",
    "plt.plot(epochs, loss, 'y', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "plt.title('Training and Validation loss', fontsize = 18, fontweight='bold')\n",
    "plt.xlabel('Epochs', fontsize=16,fontweight='bold')\n",
    "plt.ylabel('Loss', fontsize=16,fontweight='bold')\n",
    "plt.legend(fontsize=12)\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "for label in plt.gca().get_xticklabels() + plt.gca().get_yticklabels():\n",
    "    label.set_fontweight('bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf2ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7))\n",
    "\n",
    "# Train data\n",
    "plt.scatter(Y_train, y_pred, alpha=0.7, s=80, \n",
    "            label=\"Train Dataset\", color=\"#1f77b4\", edgecolor=\"k\")\n",
    "\n",
    "# Test data\n",
    "plt.scatter(Y_test, y_pred_nn, alpha=0.7, s=80, \n",
    "            label=\"Test Dataset\", color=\"#ff7f0e\", edgecolor=\"k\")\n",
    "\n",
    "# Perfect prediction line\n",
    "plt.plot([0, 10000], [0, 10000], color=\"red\", linestyle=\"--\", linewidth=2, label=\"Perfect Prediction\")\n",
    "\n",
    "# Labels with bold font\n",
    "plt.xlabel(\"Measured Value\", fontsize=28, fontweight=\"bold\")\n",
    "plt.ylabel(\"Predicted Value\", fontsize=28, fontweight=\"bold\")\n",
    "\n",
    "# Annotations\n",
    "plt.text(0.05, 0.95, \"Neural Network Regression\", fontsize=20, fontweight=\"bold\",\n",
    "         transform=plt.gca().transAxes, color=\"darkblue\")\n",
    "plt.text(0.05, 0.90, \"Training R² score = 0.98\", fontsize=18, fontweight=\"bold\",\n",
    "         transform=plt.gca().transAxes, color=\"darkgreen\")\n",
    "plt.text(0.05, 0.85, \"Testing R² score = 0.97\", fontsize=18, fontweight=\"bold\",\n",
    "         transform=plt.gca().transAxes, color=\"darkgreen\")\n",
    "\n",
    "# Legend\n",
    "plt.legend(fontsize=14, frameon=True, loc=\"lower right\", edgecolor=\"black\")\n",
    "\n",
    "# Grid\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# Bold ticks, inside placement\n",
    "plt.xticks(fontsize=14, fontweight=\"bold\")\n",
    "plt.yticks(fontsize=14, fontweight=\"bold\")\n",
    "plt.tick_params(axis=\"both\", direction=\"in\", width=2, length=6)\n",
    "\n",
    "# Bold axis spines\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_linewidth(2)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef5fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading ML regressors from sklearn library for comparison\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "lr = LinearRegression()\n",
    "dt = DecisionTreeRegressor()\n",
    "knn = KNeighborsRegressor()\n",
    "svm = SVR()\n",
    "lasso=Lasso(alpha = 0.01,max_iter =10000)\n",
    "ridge= Ridge(alpha =2,max_iter =500)\n",
    "bg = RandomForestRegressor()\n",
    "xgb = xgb.XGBRegressor(base_score=1, booster='gbtree', callbacks=None,\n",
    "             colsample_bylevel=None, colsample_bynode=None,\n",
    "             colsample_bytree=None, early_stopping_rounds=None,\n",
    "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
    "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
    "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
    "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
    "             min_child_weight=4, monotone_constraints=None,\n",
    "             n_estimators=1100, n_jobs=None, num_parallel_tree=None,\n",
    "             predictor=None, random_state=None)\n",
    "\n",
    "# Employing the dataset with ML regressors\n",
    "lr.fit(X_train, Y_train)\n",
    "dt.fit(X_train, Y_train)\n",
    "knn.fit(X_train, Y_train)\n",
    "svm.fit(X_train, Y_train)\n",
    "lasso.fit(X_train, Y_train)\n",
    "ridge.fit(X_train, Y_train)\n",
    "bg.fit(X_train, Y_train)\n",
    "xgb.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = lr.predict(X_test)\n",
    "y_pred2 = dt.predict(X_test)\n",
    "y_pred3 = knn.predict(X_test)\n",
    "y_pred4 = svm.predict(X_test)\n",
    "y_pred5 = lasso.predict(X_test)\n",
    "y_pred6 = ridge.predict(X_test)\n",
    "y_pred7 = bg.predict(X_test)\n",
    "y_pred8 = model1.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777696b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: feature column\n",
    "feature = \"feature1\"   # <-- replace with your feature name\n",
    "y_pred = model.predict(df.drop(\"Target\", axis=1))  # predicted values\n",
    "\n",
    "# Add predictions to DataFrame\n",
    "df[\"Predicted\"] = y_pred\n",
    "\n",
    "# Scatter plot: Feature vs Predicted Target\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=df[feature], y=df[\"Predicted\"], color=\"blue\", alpha=0.6, edgecolor=\"k\")\n",
    "plt.xlabel(feature, fontsize=12)\n",
    "plt.ylabel(\"Predicted Target\", fontsize=12)\n",
    "plt.title(f\"{feature} vs Predicted Target\", fontsize=14)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dcf8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "background = X_train[np.random.choice(X_train.shape[0], 40, replace=False)]\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X)\n",
    "np.shape(shap_values.values)\n",
    "\n",
    "shap.plots.waterfall(shap_values[record_number],max_display=len(X.columns))\n",
    "\n",
    "\n",
    "# Plot SHAP beeswarm\n",
    "shap.plots.beeswarm(shap_values, \n",
    "                    max_display=len(X.columns),   # top 15 features\n",
    "                    show=False)       # so we can customize before saving\n",
    "\n",
    "# --- Style adjustments for publication ---\n",
    "plt.xlabel(\"SHAP value (impact on model output)\", fontsize=16, fontweight='bold')\n",
    "plt.ylabel(\"Features\", fontsize=16, fontweight='bold')\n",
    "\n",
    "# Make ticks bold, larger, and inside\n",
    "plt.xticks(fontsize=14, fontweight='bold')\n",
    "plt.yticks(fontsize=14, fontweight='bold')\n",
    "plt.tick_params(axis='both', which='both', direction='in', length=5, width=1.5)\n",
    "\n",
    "# Bold frame\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_linewidth(1.5)\n",
    "\n",
    "# Adjust colorbar label\n",
    "cbar = plt.gcf().axes[-1]\n",
    "cbar.set_ylabel(\"Feature value (low → high)\", fontsize=14, fontweight='bold')\n",
    "cbar.tick_params(labelsize=12, width=1.5)\n",
    "\n",
    "# Tight layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6846ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP dependence bar plot\n",
    "shap.plots.bar(shap_values,max_display=len(X.columns), show=False)\n",
    "plt.xlabel(\"mean(|SHAP value|)\", fontsize=16, fontweight='bold')\n",
    "plt.ylabel(\"Features\", fontsize=16, fontweight='bold')\n",
    "\n",
    "# Make ticks bold, larger, and inside\n",
    "plt.xticks(fontsize=14, fontweight='bold')\n",
    "plt.yticks(fontsize=14, fontweight='bold')\n",
    "plt.tick_params(axis='both', which='both', direction='in', length=5, width=1.5)\n",
    "\n",
    "# Bold frame\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_linewidth(1.5)\n",
    "\n",
    "# Adjust colorbar label\n",
    "cbar = plt.gcf().axes[-1]\n",
    "cbar.set_ylabel(\"Features (low → high)\", fontsize=14, fontweight='bold')\n",
    "cbar.tick_params(labelsize=12, width=1.5)\n",
    "\n",
    "# Tight layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save high-resolution PNG\n",
    "plt.savefig(\"shap_bar_pubready.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Save as vector PDF for journal submission\n",
    "plt.savefig(\"shap_bar_pubready.pdf\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fed4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP scatter plot\n",
    "shap.plots.scatter(shap_values[:,\"col1\"],\n",
    "                  color = shap_values[:,\"col2\"],show =False)\n",
    "plt.style.use('default')   # Reset to matplotlib default\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.title(\"SHAP Dependence Plot\\ncol1 vs col2\", fontsize=18, fontweight='bold', pad=15)\n",
    "plt.xlabel(\"col1\", fontsize=14, fontweight='bold')\n",
    "plt.ylabel(\"SHAP Value for col1\", fontsize=14, fontweight='bold')\n",
    "\n",
    "# Make axes lines and tick labels bold\n",
    "plt.tick_params(axis='both', which='major', labelsize=12, width=1.5, direction='in', length=6)\n",
    "plt.gca().spines['top'].set_linewidth(1.5)\n",
    "plt.gca().spines['right'].set_linewidth(1.5)\n",
    "plt.gca().spines['left'].set_linewidth(1.5)\n",
    "plt.gca().spines['bottom'].set_linewidth(1.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
